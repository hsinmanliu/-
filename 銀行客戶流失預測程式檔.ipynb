{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (一)競賽敘述與目標\n",
    "本次競賽是給參賽者一組train data（8000筆）跟一組test data（2000筆），透過train data來做訓練，以預估test data的銀行客戶是否會流失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (二)資料前處理\n",
    "1.\n",
    "文字敘述型的資料轉成數字表示，以利於分析，\n",
    "Gender:\n",
    "Male→0 、Female→1，\n",
    "Geography:\n",
    "S0→0 、 S1→1 、 S2→2，\n",
    "但是經過後面的分析之後發現是否有將Geography的資料轉化成為數值表示並不會對結果產生顯著的影響，故捨棄\n",
    "\n",
    "2.\n",
    "留下train和test資料中對結果影響顯著的資料\n",
    "\n",
    "3.\n",
    "對剩下的資料作標準化，但是經過後面的分析之後發現並不會對結果產生顯著的影響，故捨棄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_S0</th>\n",
       "      <th>Geography_S1</th>\n",
       "      <th>Geography_S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>551</td>\n",
       "      <td>15806307</td>\n",
       "      <td>S2336</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>114051.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107577.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6897</td>\n",
       "      <td>15709621</td>\n",
       "      <td>S1500</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113088.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4588</td>\n",
       "      <td>15619340</td>\n",
       "      <td>S1865</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>119903.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132925.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>291</td>\n",
       "      <td>15620746</td>\n",
       "      <td>S1672</td>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>104257.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110857.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1673</td>\n",
       "      <td>15646372</td>\n",
       "      <td>S2532</td>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>120387.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126378.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>648</td>\n",
       "      <td>15649129</td>\n",
       "      <td>S1548</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>104472.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71641.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6113</td>\n",
       "      <td>15729557</td>\n",
       "      <td>S37</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>135715.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115928.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8957</td>\n",
       "      <td>15579112</td>\n",
       "      <td>S750</td>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>124281.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89136.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RowNumber  CustomerId Surname  CreditScore  Gender  Age  \\\n",
       "0           0        551    15806307   S2336          720       0   38   \n",
       "1           1       6897    15709621   S1500          682       0   54   \n",
       "2           2       4588    15619340   S1865          672       0   31   \n",
       "3           3        291    15620746   S1672          592       0   40   \n",
       "4           4       1673    15646372   S2532          753       0   42   \n",
       "5           5        648    15649129   S1548          575       0   42   \n",
       "6           6       6113    15729557     S37          572       0   37   \n",
       "7           7       8957    15579112    S750          753       0   34   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       5  114051.97              2          0               1   \n",
       "1       4   62397.41              1          1               0   \n",
       "2       5  119903.67              1          1               1   \n",
       "3       4  104257.86              1          1               0   \n",
       "4       5  120387.73              1          0               1   \n",
       "5       5  104472.90              1          1               1   \n",
       "6       6  135715.66              1          1               0   \n",
       "7       6  124281.61              1          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  Geography_S0  Geography_S1  Geography_S2  \n",
       "0        107577.29       0             0             0             1  \n",
       "1        113088.60       1             1             0             0  \n",
       "2        132925.17       0             1             0             0  \n",
       "3        110857.33       0             0             0             1  \n",
       "4        126378.57       0             0             0             1  \n",
       "5         71641.38       0             1             0             0  \n",
       "6        115928.95       0             1             0             0  \n",
       "7         89136.06       0             0             1             0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "train_data=pd.read_csv('C:/Users/USER/Desktop/jupyter notebook/train.csv')\n",
    "test_data=pd.read_csv('C:/Users/USER/Desktop/jupyter notebook/test.csv')\n",
    "train_data.loc[train_data['Gender']=='Male', 'Gender']=0\n",
    "test_data.loc[test_data['Gender']=='Male','Gender']=0\n",
    "train_data.loc[train_data['Gender']=='Female', 'Gender']=0\n",
    "test_data.loc[test_data['Gender']=='Female','Gender']=1\n",
    "train_data1=pd.get_dummies(train_data,columns=['Geography'])\n",
    "test_data1=pd.get_dummies(test_data,columns=['Geography'])\n",
    "train_data1.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11)\n",
      "(8000,)\n",
      "(2000, 11)\n"
     ]
    }
   ],
   "source": [
    "X=train_data[['RowNumber','CustomerId','CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary']]\n",
    "y=np.array(train_data['Exited'])\n",
    "X_TEST=test_data[['RowNumber','CustomerId','CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary']]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 14)\n",
      "(8000,)\n",
      "(2000, 14)\n"
     ]
    }
   ],
   "source": [
    "X=train_data1[['RowNumber','CustomerId','CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Geography_S0','Geography_S1','Geography_S2']]\n",
    "y=np.array(train_data1['Exited'])\n",
    "X_TEST=test_data1[['RowNumber','CustomerId','CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Geography_S0','Geography_S1','Geography_S2']]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN \n",
    "# outlier_detection = DBSCAN( eps = 0.5, metric=\"euclidean\", min_samples = 3, n_jobs = -1) \n",
    "# clusters = outlier_detection.fit_predict(credit_EstimatedSalary) \n",
    "# print(-1 in clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=123)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706762</td>\n",
       "      <td>0.368730</td>\n",
       "      <td>0.294462</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-1.455309</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>1.319972</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.831273</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.716165</td>\n",
       "      <td>0.507565</td>\n",
       "      <td>-1.275071</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>2.668447</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.440776</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.939935</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.374388</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>1.425200</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.673081</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>1.715706</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.683423</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.218994</td>\n",
       "      <td>-1.415308</td>\n",
       "      <td>-2.203289</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>2.535423</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.600059</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.303826</td>\n",
       "      <td>-0.405184</td>\n",
       "      <td>-1.072550</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.140984</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.310798</td>\n",
       "      <td>2.519206</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.551893</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.361081</td>\n",
       "      <td>-1.361148</td>\n",
       "      <td>-0.464989</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>0.968768</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.407998</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.768759</td>\n",
       "      <td>0.297490</td>\n",
       "      <td>-1.275071</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.790187</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>1.317609</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.223261</td>\n",
       "      <td>-1.661225</td>\n",
       "      <td>1.948378</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>1.205179</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>0.194329</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-1.102243</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.177257</td>\n",
       "      <td>-1.489357</td>\n",
       "      <td>-0.414359</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-1.189260</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.795706</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.725064</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.479495</td>\n",
       "      <td>1.307057</td>\n",
       "      <td>-2.355179</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-1.588333</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>1.511190</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.632916</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.105195</td>\n",
       "      <td>1.203758</td>\n",
       "      <td>1.914624</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.444006</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.853531</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.676862</td>\n",
       "      <td>-1.496534</td>\n",
       "      <td>2.049638</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>1.072154</td>\n",
       "      <td>1.897273</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-1.153513</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.647769</td>\n",
       "      <td>-0.034521</td>\n",
       "      <td>-1.021920</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>2.535423</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.291423</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.424215</td>\n",
       "      <td>0.175595</td>\n",
       "      <td>-0.735017</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>0.673081</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.074252</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.767257</td>\n",
       "      <td>1.295276</td>\n",
       "      <td>1.222680</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>0.806106</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>-0.048807</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.136961</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.866454</td>\n",
       "      <td>-1.366947</td>\n",
       "      <td>1.813364</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.864317</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-1.077095</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.109130</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.429475</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.258089</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>1.647301</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.718708</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.810716</td>\n",
       "      <td>-0.910761</td>\n",
       "      <td>0.834516</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-1.588333</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.626814</td>\n",
       "      <td>-0.638111</td>\n",
       "      <td>-0.110579</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.790187</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.945770</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.987989</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.734924</td>\n",
       "      <td>-1.262842</td>\n",
       "      <td>-0.650633</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.923211</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.029354</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.540338</td>\n",
       "      <td>-1.068595</td>\n",
       "      <td>-1.426961</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>0.237003</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>1.538132</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.388547</td>\n",
       "      <td>-0.917242</td>\n",
       "      <td>1.796487</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.657163</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.993479</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.285052</td>\n",
       "      <td>0.854069</td>\n",
       "      <td>-0.144332</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>1.722718</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.776407</td>\n",
       "      <td>0.111866</td>\n",
       "      <td>0.091941</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.391114</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.392625</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.279512</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.667839</td>\n",
       "      <td>1.044213</td>\n",
       "      <td>-0.600003</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.391114</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.060477</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.567693</td>\n",
       "      <td>1.168277</td>\n",
       "      <td>1.458954</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.673081</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.659284</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.010501</td>\n",
       "      <td>-0.414359</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.258089</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.709355</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.034190</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.369520</td>\n",
       "      <td>-0.228518</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.111028</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.324228</td>\n",
       "      <td>1.340882</td>\n",
       "      <td>2.049638</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.258089</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.712328</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.593298</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.008289</td>\n",
       "      <td>-0.095232</td>\n",
       "      <td>-1.275071</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.673081</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.461397</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>-0.441947</td>\n",
       "      <td>-1.061891</td>\n",
       "      <td>0.345092</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.140984</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.717921</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>-0.596661</td>\n",
       "      <td>1.504378</td>\n",
       "      <td>0.834516</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>1.205179</td>\n",
       "      <td>1.897273</td>\n",
       "      <td>1.059324</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.525415</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>0.011766</td>\n",
       "      <td>-0.757015</td>\n",
       "      <td>-2.304549</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-1.531104</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>-0.599442</td>\n",
       "      <td>-0.898257</td>\n",
       "      <td>-0.735017</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.327808</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>1.152130</td>\n",
       "      <td>-1.499385</td>\n",
       "      <td>1.847117</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.146022</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>-0.708959</td>\n",
       "      <td>-1.652629</td>\n",
       "      <td>-0.886907</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>1.471227</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.333030</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.835067</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>0.536055</td>\n",
       "      <td>-1.118666</td>\n",
       "      <td>0.885146</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.258089</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.054403</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>0.328147</td>\n",
       "      <td>0.941067</td>\n",
       "      <td>1.661474</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>2.269374</td>\n",
       "      <td>1.897273</td>\n",
       "      <td>-0.177421</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.704098</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>-0.140515</td>\n",
       "      <td>-1.403026</td>\n",
       "      <td>-0.262469</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>0.569228</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.812480</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>0.725189</td>\n",
       "      <td>0.904696</td>\n",
       "      <td>1.087666</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.657163</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.277555</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>0.119544</td>\n",
       "      <td>-0.791397</td>\n",
       "      <td>-0.836277</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.391114</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.268729</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>-0.808046</td>\n",
       "      <td>-1.018288</td>\n",
       "      <td>0.176325</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.790187</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>0.928866</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-1.685959</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>-1.310780</td>\n",
       "      <td>0.305279</td>\n",
       "      <td>-1.207564</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.524138</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>0.922335</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>-0.552159</td>\n",
       "      <td>0.251147</td>\n",
       "      <td>-1.173811</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-0.068162</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-1.565514</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>1.343002</td>\n",
       "      <td>-0.262010</td>\n",
       "      <td>-0.735017</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-1.455309</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>0.318638</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.944392</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>0.996373</td>\n",
       "      <td>1.153854</td>\n",
       "      <td>1.374570</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>1.471227</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.955552</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>0.319108</td>\n",
       "      <td>1.516506</td>\n",
       "      <td>0.361968</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>0.806106</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>0.249652</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.024248</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>0.419933</td>\n",
       "      <td>-0.889633</td>\n",
       "      <td>-1.376331</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.731848</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-0.477478</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>0.259656</td>\n",
       "      <td>0.119641</td>\n",
       "      <td>-1.747618</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.140984</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.501896</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>0.314024</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>-1.351457</td>\n",
       "      <td>1.139820</td>\n",
       "      <td>-1.443838</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>0.806106</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.255938</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>-0.595965</td>\n",
       "      <td>0.187237</td>\n",
       "      <td>-0.515620</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-1.189260</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.610835</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.703420</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>0.569779</td>\n",
       "      <td>0.233775</td>\n",
       "      <td>1.222680</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>2.801471</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>1.734858</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>1.036639</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>-1.630986</td>\n",
       "      <td>0.545855</td>\n",
       "      <td>-0.346853</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.125065</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.306544</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>1.769007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>-1.496784</td>\n",
       "      <td>-1.011834</td>\n",
       "      <td>-0.245592</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>0.540057</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.870511</td>\n",
       "      <td>2.519206</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>-1.042920</td>\n",
       "      <td>-1.580423</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>0.124064</td>\n",
       "      <td>0.830814</td>\n",
       "      <td>1.307063</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>-1.189260</td>\n",
       "      <td>-1.246076</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>1.577420</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>-1.703997</td>\n",
       "      <td>1.427867</td>\n",
       "      <td>-1.393208</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>0.540057</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>0.479767</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.462839</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>-0.124870</td>\n",
       "      <td>1.084506</td>\n",
       "      <td>1.307063</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-1.189260</td>\n",
       "      <td>-2.031913</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.207142</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>-1.427250</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.345092</td>\n",
       "      <td>-0.918015</td>\n",
       "      <td>2.003325</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-1.217593</td>\n",
       "      <td>2.519206</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.431019</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>-0.588385</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1.022796</td>\n",
       "      <td>1.205830</td>\n",
       "      <td>0.530735</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.923211</td>\n",
       "      <td>-0.460239</td>\n",
       "      <td>0.746115</td>\n",
       "      <td>-0.918419</td>\n",
       "      <td>-1.567869</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-0.299106</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0.239491</td>\n",
       "      <td>0.600432</td>\n",
       "      <td>-1.308824</td>\n",
       "      <td>1.089307</td>\n",
       "      <td>-0.657163</td>\n",
       "      <td>0.325599</td>\n",
       "      <td>0.904619</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.637808</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>-1.709616</td>\n",
       "      <td>-1.001334</td>\n",
       "      <td>1.699567</td>\n",
       "      <td>-0.565289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.706762  0.368730  0.294462 -0.918015 -1.455309  0.325599  1.319972   \n",
       "1    -1.716165  0.507565 -1.275071 -0.918015  2.668447  1.111436  0.440776   \n",
       "2     0.374388  0.051239  1.425200 -0.918015  0.673081  1.111436  1.715706   \n",
       "3    -1.218994 -1.415308 -2.203289  1.089307  2.535423  1.111436 -1.217593   \n",
       "4    -1.303826 -0.405184 -1.072550 -0.918015  0.140984  1.111436  0.310798   \n",
       "5     1.361081 -1.361148 -0.464989  1.089307 -0.125065 -0.460239  0.968768   \n",
       "6    -0.768759  0.297490 -1.275071  1.089307 -0.790187  0.325599 -1.217593   \n",
       "7    -0.223261 -1.661225  1.948378  1.089307  1.205179 -1.246076  0.194329   \n",
       "8     0.177257 -1.489357 -0.414359  1.089307 -1.189260  0.325599  0.795706   \n",
       "9    -0.479495  1.307057 -2.355179  1.089307 -1.588333  0.325599  1.511190   \n",
       "10    1.105195  1.203758  1.914624 -0.918015  0.939130  1.111436  0.444006   \n",
       "11    0.676862 -1.496534  2.049638  1.089307  1.072154  1.897273 -1.217593   \n",
       "12   -0.647769 -0.034521 -1.021920 -0.918015  2.535423  1.111436 -1.217593   \n",
       "13   -0.424215  0.175595 -0.735017  1.089307  0.673081 -1.246076 -1.217593   \n",
       "14    0.767257  1.295276  1.222680  1.089307  0.806106 -0.460239 -0.048807   \n",
       "15   -0.866454 -1.366947  1.813364 -0.918015 -0.524138  1.111436  0.864317   \n",
       "16   -1.109130  0.684524  0.429475 -0.918015 -0.258089  1.111436  1.647301   \n",
       "17    0.810716 -0.910761  0.834516 -0.918015 -1.588333  0.325599 -1.217593   \n",
       "18   -1.626814 -0.638111 -0.110579 -0.918015 -0.790187  1.111436  0.945770   \n",
       "19    0.734924 -1.262842 -0.650633 -0.918015 -0.923211 -1.246076 -1.217593   \n",
       "20   -0.540338 -1.068595 -1.426961 -0.918015 -0.125065 -1.246076  0.237003   \n",
       "21    1.388547 -0.917242  1.796487  1.089307 -0.657163 -1.246076 -1.217593   \n",
       "22   -1.285052  0.854069 -0.144332  1.089307 -0.524138  0.325599 -1.217593   \n",
       "23   -0.776407  0.111866  0.091941 -0.918015 -0.391114  1.111436  0.392625   \n",
       "24   -1.667839  1.044213 -0.600003 -0.918015 -0.391114 -1.246076 -1.217593   \n",
       "25    0.567693  1.168277  1.458954 -0.918015  0.673081  0.325599 -1.217593   \n",
       "26   -0.010833 -0.010501 -0.414359  1.089307 -0.258089  0.325599  0.709355   \n",
       "27    0.369520 -0.228518  0.159448  1.089307 -0.524138  0.325599 -1.217593   \n",
       "28    1.324228  1.340882  2.049638 -0.918015 -0.258089  0.325599  0.712328   \n",
       "29    0.008289 -0.095232 -1.275071 -0.918015  0.673081  1.111436 -1.217593   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5970 -0.441947 -1.061891  0.345092 -0.918015  0.140984  0.325599 -0.012891   \n",
       "5971 -0.596661  1.504378  0.834516 -0.918015  1.205179  1.897273  1.059324   \n",
       "5972  0.011766 -0.757015 -2.304549 -0.918015 -0.125065  1.111436 -1.217593   \n",
       "5973 -0.599442 -0.898257 -0.735017 -0.918015 -0.524138 -1.246076 -1.217593   \n",
       "5974  1.152130 -1.499385  1.847117  1.089307 -0.524138 -1.246076 -1.217593   \n",
       "5975 -0.708959 -1.652629 -0.886907 -0.918015  1.471227  1.111436  0.333030   \n",
       "5976  0.536055 -1.118666  0.885146 -0.918015 -0.258089  0.325599 -1.217593   \n",
       "5977  0.328147  0.941067  1.661474  1.089307  2.269374  1.897273 -0.177421   \n",
       "5978 -0.140515 -1.403026 -0.262469 -0.918015  0.939130 -0.460239  0.569228   \n",
       "5979  0.725189  0.904696  1.087666 -0.918015 -0.657163  1.111436 -1.217593   \n",
       "5980  0.119544 -0.791397 -0.836277  1.089307 -0.391114  1.111436 -1.217593   \n",
       "5981 -0.808046 -1.018288  0.176325 -0.918015 -0.790187 -0.460239  0.928866   \n",
       "5982 -1.310780  0.305279 -1.207564 -0.918015 -0.524138 -1.246076  0.922335   \n",
       "5983 -0.552159  0.251147 -1.173811 -0.918015 -0.125065  1.111436 -0.068162   \n",
       "5984  1.343002 -0.262010 -0.735017  1.089307 -1.455309 -0.460239  0.318638   \n",
       "5985  0.996373  1.153854  1.374570  1.089307  1.471227 -1.246076 -1.217593   \n",
       "5986  0.319108  1.516506  0.361968  1.089307  0.806106 -1.246076  0.249652   \n",
       "5987  0.419933 -0.889633 -1.376331 -0.918015  0.939130  0.325599  0.731848   \n",
       "5988  0.259656  0.119641 -1.747618 -0.918015  0.140984  0.325599  0.501896   \n",
       "5989 -1.351457  1.139820 -1.443838 -0.918015  0.806106 -1.246076 -1.217593   \n",
       "5990 -0.595965  0.187237 -0.515620  1.089307 -1.189260  1.111436  0.610835   \n",
       "5991  0.569779  0.233775  1.222680  1.089307  2.801471 -1.246076  1.734858   \n",
       "5992 -1.630986  0.545855 -0.346853  1.089307 -0.125065  0.325599 -1.217593   \n",
       "5993 -1.496784 -1.011834 -0.245592  1.089307  0.540057  0.325599  0.870511   \n",
       "5994  0.124064  0.830814  1.307063 -0.918015 -1.189260 -1.246076 -1.217593   \n",
       "5995 -1.703997  1.427867 -1.393208  1.089307  0.540057  1.111436  0.479767   \n",
       "5996 -0.124870  1.084506  1.307063  1.089307 -1.189260 -2.031913 -1.217593   \n",
       "5997 -1.427250  0.292135  0.345092 -0.918015  2.003325  1.111436 -1.217593   \n",
       "5998  1.022796  1.205830  0.530735  1.089307 -0.923211 -0.460239  0.746115   \n",
       "5999  0.239491  0.600432 -1.308824  1.089307 -0.657163  0.325599  0.904619   \n",
       "\n",
       "            7         8         9         10        11        12        13  \n",
       "0    -0.918419 -1.567869 -1.042920  0.831273  0.998668 -0.588385 -0.565289  \n",
       "1     0.800394  0.637808  0.958846  0.939935  0.998668 -0.588385 -0.565289  \n",
       "2    -0.918419 -1.567869 -1.042920  0.683423 -1.001334 -0.588385  1.769007  \n",
       "3    -0.918419  0.637808 -1.042920 -0.600059  0.998668 -0.588385 -0.565289  \n",
       "4     2.519206  0.637808  0.958846  0.551893 -1.001334  1.699567 -0.565289  \n",
       "5    -0.918419 -1.567869 -1.042920  1.407998 -1.001334  1.699567 -0.565289  \n",
       "6     0.800394  0.637808  0.958846  1.317609  0.998668 -0.588385 -0.565289  \n",
       "7    -0.918419 -1.567869  0.958846 -1.102243 -1.001334  1.699567 -0.565289  \n",
       "8    -0.918419  0.637808 -1.042920  1.725064  0.998668 -0.588385 -0.565289  \n",
       "9     0.800394 -1.567869  0.958846  0.632916 -1.001334 -0.588385  1.769007  \n",
       "10   -0.918419  0.637808  0.958846 -0.853531  0.998668 -0.588385 -0.565289  \n",
       "11    0.800394  0.637808  0.958846 -1.153513 -1.001334 -0.588385  1.769007  \n",
       "12    0.800394  0.637808  0.958846  0.291423 -1.001334 -0.588385  1.769007  \n",
       "13    0.800394  0.637808 -1.042920  0.074252 -1.001334 -0.588385  1.769007  \n",
       "14    0.800394  0.637808  0.958846  0.136961 -1.001334 -0.588385  1.769007  \n",
       "15    0.800394 -1.567869 -1.042920 -1.077095  0.998668 -0.588385 -0.565289  \n",
       "16   -0.918419 -1.567869 -1.042920 -0.718708  0.998668 -0.588385 -0.565289  \n",
       "17    0.800394  0.637808  0.958846  0.299336  0.998668 -0.588385 -0.565289  \n",
       "18   -0.918419 -1.567869 -1.042920 -0.987989 -1.001334  1.699567 -0.565289  \n",
       "19    0.800394 -1.567869  0.958846 -0.029354  0.998668 -0.588385 -0.565289  \n",
       "20   -0.918419  0.637808  0.958846  1.538132 -1.001334  1.699567 -0.565289  \n",
       "21    0.800394  0.637808  0.958846 -0.993479 -1.001334 -0.588385  1.769007  \n",
       "22    0.800394  0.637808  0.958846  1.722718  0.998668 -0.588385 -0.565289  \n",
       "23   -0.918419  0.637808 -1.042920 -0.279512  0.998668 -0.588385 -0.565289  \n",
       "24    0.800394  0.637808 -1.042920  0.060477  0.998668 -0.588385 -0.565289  \n",
       "25    0.800394  0.637808 -1.042920  1.659284  0.998668 -0.588385 -0.565289  \n",
       "26    0.800394  0.637808 -1.042920  1.034190 -1.001334 -0.588385  1.769007  \n",
       "27    0.800394  0.637808 -1.042920  1.111028 -1.001334 -0.588385  1.769007  \n",
       "28   -0.918419  0.637808 -1.042920  1.593298 -1.001334  1.699567 -0.565289  \n",
       "29   -0.918419 -1.567869 -1.042920  0.461397  0.998668 -0.588385 -0.565289  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5970 -0.918419  0.637808 -1.042920  1.717921 -1.001334 -0.588385  1.769007  \n",
       "5971 -0.918419  0.637808 -1.042920  0.525415  0.998668 -0.588385 -0.565289  \n",
       "5972  0.800394  0.637808  0.958846 -1.531104  0.998668 -0.588385 -0.565289  \n",
       "5973  0.800394 -1.567869  0.958846 -0.327808 -1.001334 -0.588385  1.769007  \n",
       "5974  0.800394 -1.567869 -1.042920  1.146022  0.998668 -0.588385 -0.565289  \n",
       "5975 -0.918419 -1.567869 -1.042920 -0.835067  0.998668 -0.588385 -0.565289  \n",
       "5976  0.800394  0.637808  0.958846 -0.054403 -1.001334 -0.588385  1.769007  \n",
       "5977  0.800394 -1.567869  0.958846  0.704098  0.998668 -0.588385 -0.565289  \n",
       "5978 -0.918419 -1.567869  0.958846  0.812480 -1.001334 -0.588385  1.769007  \n",
       "5979  0.800394  0.637808 -1.042920  0.277555  0.998668 -0.588385 -0.565289  \n",
       "5980  0.800394 -1.567869 -1.042920 -0.268729  0.998668 -0.588385 -0.565289  \n",
       "5981 -0.918419 -1.567869 -1.042920 -1.685959 -1.001334 -0.588385  1.769007  \n",
       "5982 -0.918419  0.637808  0.958846  0.179181  0.998668 -0.588385 -0.565289  \n",
       "5983  0.800394  0.637808  0.958846 -1.565514 -1.001334 -0.588385  1.769007  \n",
       "5984 -0.918419  0.637808  0.958846 -0.944392  0.998668 -0.588385 -0.565289  \n",
       "5985  0.800394  0.637808 -1.042920 -0.955552 -1.001334 -0.588385  1.769007  \n",
       "5986 -0.918419 -1.567869 -1.042920  1.024248 -1.001334  1.699567 -0.565289  \n",
       "5987 -0.918419  0.637808 -1.042920 -0.477478  0.998668 -0.588385 -0.565289  \n",
       "5988  0.800394 -1.567869 -1.042920  0.314024 -1.001334  1.699567 -0.565289  \n",
       "5989 -0.918419  0.637808  0.958846  0.255938 -1.001334 -0.588385  1.769007  \n",
       "5990 -0.918419  0.637808 -1.042920  1.703420 -1.001334  1.699567 -0.565289  \n",
       "5991 -0.918419 -1.567869 -1.042920  1.036639  0.998668 -0.588385 -0.565289  \n",
       "5992  0.800394  0.637808  0.958846  0.306544 -1.001334 -0.588385  1.769007  \n",
       "5993  2.519206  0.637808 -1.042920 -1.580423 -1.001334  1.699567 -0.565289  \n",
       "5994  0.800394  0.637808  0.958846  1.577420  0.998668 -0.588385 -0.565289  \n",
       "5995  0.800394  0.637808  0.958846 -0.462839  0.998668 -0.588385 -0.565289  \n",
       "5996  0.800394 -1.567869  0.958846  0.207142  0.998668 -0.588385 -0.565289  \n",
       "5997  2.519206  0.637808  0.958846 -0.431019  0.998668 -0.588385 -0.565289  \n",
       "5998 -0.918419 -1.567869  0.958846 -0.299106 -1.001334  1.699567 -0.565289  \n",
       "5999  0.800394  0.637808  0.958846 -1.709616 -1.001334  1.699567 -0.565289  \n",
       "\n",
       "[6000 rows x 14 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)\n",
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (三)特徵處理與分析\n",
    "Accuracy=所有預測出會離開（1）、不會離開（0）的正確率\n",
    "\n",
    "Precision=測試資料預估為1中真的為1的比例\n",
    "\n",
    "Recall =測試資料中答案為1中正確分類為1的比例\n",
    "\n",
    "fScore =(2xPrecisionxRecall)/(Precision+Recall)\n",
    "\n",
    "final = 30%Accuracy+30%Precision+40%fScore\n",
    "\n",
    "我們令多個方程式計算這些數值，以觀察資料及分析1、0的正確率是否接近完美。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(a,b,c):\n",
    "    final=(a*0.3)+(b*0.3)+(c*0.4)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(test,pred):\n",
    "    TP,FP,FN,TN=0,0,0,0\n",
    "    for i in range(len(test)):\n",
    "        if pred[i]==1 and test[i]==1:\n",
    "            TP+=1\n",
    "        elif pred[i]==1 and test[i]!=1:\n",
    "            FP+=1\n",
    "        elif pred[i]!=1 and test[i]==1:\n",
    "            FN+=1\n",
    "        elif pred[i]!=1 and test[i]!=1:\n",
    "            TN+=1\n",
    "    return TP,FP,FN,TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_fscore(a):\n",
    "    precision=a[0]/(a[0]+a[1])\n",
    "    recall=a[0]/(a[0]+a[2])\n",
    "    fscore=2*precision*recall/(precision+recall)\n",
    "    return precision,recall,fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (四)預測訓練模型\n",
    "\n",
    "KNeighborsClassifier、PCA、GaussianNB、AdaBoostClassifier、BaggingClassifier、ExtraTreesClassifier、GradientBoostingClassifier、RidgeClassifierCV、RandomForestClassifier、Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ◆KNeighborsClassifier\n",
    "###    n=26,accuracy=0.7885,precision=1.0,recall=0.047,fscore=0.097,final=0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-144146e4753d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpre1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.model_selection import \n",
    "knn=KNeighborsClassifier(n_neighbors=6)\n",
    "print(type(knn))\n",
    "knn.fit(X_train,y_train)\n",
    "pre1=knn.predict(X_test)\n",
    "accuracy=knn.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre1)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-aa46538bc1da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpre1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=20)\n",
    "print(type(knn))\n",
    "knn.fit(X_train,y_train)\n",
    "pre1=knn.predict(X_test)\n",
    "accuracy=knn.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre1)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 本來想嘗試如果降到一維做看結果如何，結果非常差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1=KNeighborsClassifier(n_neighbors=28)\n",
    "knn1.fit(pd.DataFrame(X_train['CreditScore']),y_train)\n",
    "pre=knn1.predict(pd.DataFrame(X_test['CreditScore']))\n",
    "print(pre[:100])\n",
    "print(y_test)\n",
    "accuracy=knn1.score(pd.DataFrame(X_test['CreditScore']),y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ◆GaussianNB\n",
    "### var_smoothing=0, accuracy:0.817,precision=0.718,recall=0.228,fscore=0.346,final=0.5992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  0.7896085611498915\n",
      "1:  0.2103914388501084\n",
      "0.8075\n",
      "(0.5757575757575758, 0.35764705882352943, 0.4412191582002903)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5914649360073888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gau=GaussianNB(var_smoothing = 0)\n",
    "gau.fit(X_train,y_train)\n",
    "pre2=gau.predict(X_test)\n",
    "gau_proba=gau.predict_proba(X_test)\n",
    "print('0: ',gau_proba[:,0].mean())\n",
    "print('1: ',gau_proba[:,1].mean())\n",
    "# print(pre1[:50])\n",
    "# print(np.array(y_test[:50]))\n",
    "accuracy=gau.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre2)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gau1=GaussianNB(var_smoothing = 0 )\n",
    "pre2=gau.predict(X_TEST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆AdaBoostClassifier\n",
    "### n_estimators=200,learning_rate=0.2,accuracy=0.859,precision=0.78,recall=0.466,fscore=0.584,final=0.726\n",
    "### n_estimator=100,learning_rate=0.5,accuracy=0.858,precision=0.77,recall=0.47,fscore=0.584,final=0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52313472 0.47686528]\n",
      " [0.51438893 0.48561107]\n",
      " [0.51365333 0.48634667]\n",
      " ...\n",
      " [0.50583282 0.49416718]\n",
      " [0.50912325 0.49087675]\n",
      " [0.49540073 0.50459927]]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
      "0.8585\n",
      "(0.77734375, 0.4682352941176471, 0.5844346549192364)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7245269869676946"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=200,learning_rate=0.2,random_state=123)\n",
    "ada.fit(X_train,y_train)\n",
    "pre3=ada.predict(X_test)\n",
    "ada_tproba=ada.predict_proba(X_test)\n",
    "print(ada_tproba)\n",
    "print(pre3[:50])\n",
    "print(np.array(y_test[0:50]))\n",
    "accuracy=ada.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre3)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.fit(X,y)\n",
    "ada_proba=ada.predict_proba(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆BaggingClassifier\n",
    "### n_estimators=500,accuracy=0.8605,precision=0.789,recall=0.468,fscore=0.587,final=0.682(NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.938 0.062]\n",
      " [0.99  0.01 ]\n",
      " [0.984 0.016]\n",
      " ...\n",
      " [0.84  0.16 ]\n",
      " [0.704 0.296]\n",
      " [0.626 0.374]]\n",
      "0.863\n",
      "(0.7785977859778598, 0.4964705882352941, 0.6063218390804598)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6910675710874755"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.fit(X,y)\n",
    "bag_proba=bag.predict_proba(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆ExtraTreesClassifier\n",
    "### n_estimators=600,random_state=1234,accuracy=0.8585,precision=0.825,recall=0.4235,fscore=0.5598,final=0.729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98166667 0.01833333]\n",
      " [0.93333333 0.06666667]\n",
      " [0.905      0.095     ]\n",
      " ...\n",
      " [0.68833333 0.31166667]\n",
      " [0.75       0.25      ]\n",
      " [0.52166667 0.47833333]]\n",
      "0.8525\n",
      "(0.825, 0.38823529411764707, 0.528)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra=ExtraTreesClassifier(n_estimators=600,random_state=123)\n",
    "extra.fit(X_train,y_train)\n",
    "pre5=extra.predict(X_test)\n",
    "tree_tproba=extra.predict_proba(X_test)\n",
    "print(tree_tproba)\n",
    "accuracy=extra.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre5)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra.fit(X,y)\n",
    "tree_proba=extra.predict_proba(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆GradientBoostingClassifier\n",
    "### n_estimators=200,learn_rate=0.02,random_state=1234,accuracy=0.8635,precision=0.85,recall=0.435,\n",
    "### fscore=0.575,final=0.743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9536196  0.0463804 ]\n",
      " [0.87455456 0.12544544]\n",
      " [0.86545789 0.13454211]\n",
      " ...\n",
      " [0.72978384 0.27021616]\n",
      " [0.8297544  0.1702456 ]\n",
      " [0.22425844 0.77574156]]\n",
      "0.864\n",
      "(0.8525345622119815, 0.43529411764705883, 0.5763239875389408)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7454899636791708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grad=GradientBoostingClassifier(n_estimators=200,learning_rate=0.02,random_state=1234)\n",
    "grad.fit(X_train,y_train)\n",
    "pre6=grad.predict(X_test)\n",
    "boost_tproba=grad.predict_proba(X_test)\n",
    "print(boost_tproba)\n",
    "accuracy=grad.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre6)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.fit(X,y)\n",
    "boost_proba=grad.predict_proba(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ◆RidgeClassifierCV\n",
    "覺得沒有明顯幫助，故不採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "rid= RidgeClassifierCV()\n",
    "rid.fit(X_train,y_train)\n",
    "pre1=rid.predict(X_test)\n",
    "accuracy=rid.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre1)\n",
    "ans=precision_recall_fscore(right)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ◆RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_=RandomForestClassifier(n_estimators=200,random_state=123)\n",
    "random_.fit(X_train,y_train)\n",
    "pre6=random_.predict(X_test)\n",
    "accuracy=random_.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "a=np.array(y_test)\n",
    "d=a.ravel()\n",
    "right=classifier(d,pre6) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "覺得沒有明顯幫助，故不採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(min_samples_split=1.5,random_state=5432)\n",
    "dtree.fit(X_train,y_train)\n",
    "pre=dtree.predict(X_test)\n",
    "accuracy=dtree.score(X_test,y_test)\n",
    "print(accuracy)\n",
    "right=classifier(y_test,pre)\n",
    "ans=precision_recall_fscore(right)\n",
    "print(ans)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "print(s)\n",
    "from sklearn.metrics import classification_report\n",
    "ss= classification_report(y_test,pre)\n",
    "ss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(X,y)\n",
    "pre2=dtree.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada:   [0 1 1 0 0 1 0 0 0 0] [0.4994692 0.5005308]\n",
      "boo:   [0 0 1 0 0 1 0 0 0 1] [0.59615704 0.40384296]\n",
      "tree:  [0 0 1 0 0 1 0 0 0 1]\n",
      "bag:   [0 0 1 0 0 1 0 0 0 1]\n",
      "this:  [0 0 1 0 0 1 0 0 0 1] [0.96136579 0.70530088]\n",
      "real:  [0 1 1 0 0 1 0 0 0 1]\n",
      "0.864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7454899636791708"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tproba=((boost_tproba*4)+(ada_tproba*1)+(tree_tproba*0)+(bag_tproba*0))/3\n",
    "# print(boost_tproba[:50],ada_tproba[:50])\n",
    "# print(pre_tproba[:50])\n",
    "print('ada:  ',pre3[60:70],ada_tproba[61])\n",
    "print('boo:  ',pre6[60:70],boost_tproba[61])\n",
    "print('tree: ',pre5[60:70])\n",
    "print('bag:  ',pre4[60:70])\n",
    "pre1=[]\n",
    "for i in range(len(pre_tproba)):\n",
    "    if pre_tproba[i][0]>pre_tproba[i][1]:\n",
    "        pre1.append(0)\n",
    "    else:\n",
    "        pre1.append(1)\n",
    "pre1=np.array(pre1)\n",
    "print('this: ',pre1[60:70],pre_tproba[61])\n",
    "print('real: ',y_test[60:70])\n",
    "right=classifier(y_test,pre1)\n",
    "accuracy=(right[0]+right[3])/sum(right)\n",
    "print(accuracy)\n",
    "ans=precision_recall_fscore(right)\n",
    "s=final(accuracy,ans[0],ans[2])\n",
    "s\n",
    "#0.7454899636791708\n",
    "#0.7454899636791708"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ada,bagging,extratrees,boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##boost>ada>trees>bagging\n",
    "pre_proba=((boost_proba*2)+(ada_proba*1)+(tree_proba*0)+(bag_proba*0))/3\n",
    "pre2=[]\n",
    "for i in range(len(pre_proba)):\n",
    "    if pre_proba[i][0]>pre_proba[i][1]:\n",
    "        pre2.append(0)\n",
    "    else:\n",
    "        pre2.append(1)\n",
    "pre2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 輸出結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "anss=pd.DataFrame({'RowNumber':X_TEST['RowNumber'],'Exited':pre2})\n",
    "anss.index=range(len(anss))\n",
    "anss.to_csv('upload.csv',columns=['RowNumber','Exited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (六)預測結果分析\n",
    "我們將原本的traindata 再分成train 和 test ，再針對準確率看起來比較高的package，進行不同的參數做test的預測，觀察最好的結果是發生在哪段參數的範圍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier\n",
    "當時我們在作時並沒有畫圖分析，就是徒手改參數，現在畫出來發現大概在400時，final score 才會是最好的，而我們卻只設參數到200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xbd45910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_est=[100,200,300,400,500]\n",
    "s=[]\n",
    "fs=[]\n",
    "acc=[]\n",
    "for n in n_est:\n",
    "    ada=AdaBoostClassifier(n_estimators=n,learning_rate=0.2,random_state=123)\n",
    "    ada.fit(X_train,y_train)\n",
    "    pre1=ada.predict(X_test)\n",
    "    accuracy=ada.score(X_test,y_test)\n",
    "    right=classifier(y_test,pre1)\n",
    "    ans=precision_recall_fscore(right)\n",
    "    ss=final(accuracy,ans[0],ans[2])\n",
    "    acc+=[accuracy]\n",
    "    fs+=[ans[2]]\n",
    "    s+=[ss]\n",
    "plt.plot(n_est,s,c='red',label='final')\n",
    "plt.plot(n_est,fs,c='blue',label='fscore')\n",
    "plt.plot(n_est,acc,c='green',label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier\n",
    "我們當時設參數500，但現在畫圖發現設在600~700可能會更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xbd0d050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "b=[100,200,300,400,500,600,700,800,900,1000]\n",
    "s=[]\n",
    "fs=[]\n",
    "acc=[]\n",
    "for bb in b:\n",
    "    bag=BaggingClassifier(n_estimators=bb,random_state=123)\n",
    "    bag.fit(X_train,y_train)\n",
    "    pre1=bag.predict(X_test)\n",
    "    accuracy=bag.score(X_test,y_test)\n",
    "    right=classifier(y_test,pre1)\n",
    "    ans=precision_recall_fscore(right)\n",
    "    ss=final(accuracy,ans[0],ans[2])\n",
    "    acc+=[accuracy]\n",
    "    fs+=[ans[2]]\n",
    "    s+=[ss]\n",
    "plt.plot(b,s,c='red',label='final')\n",
    "plt.plot(b,fs,c='blue',label='fscore')\n",
    "plt.plot(b,acc,c='green',label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xd081d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X10VPW97/H3N5OQEBAIJNRCpIEWLSiPDpSKFdCK1LagqC3IaYFrZbmO1FNtT0WPrVW7uri9txW1tJR6UWs9pb14VK7LhyWKD7WIhCOtlQdFQE2xGkHAFIJ5+N4/9p5kMuRhEkImyf681tpr9v79fnvmNzs7n9n57Z095u6IiEg0ZGW6AyIi0nEU+iIiEaLQFxGJEIW+iEiEKPRFRCJEoS8iEiEKfRGRCFHoi4hEiEJfRCRCsjPdgVSFhYVeUlKS6W6IiHQpmzdv/sDdi1pq1+lCv6SkhNLS0kx3Q0SkSzGzt9Jpp+EdEZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJEIW+iEiEKPRFRCKk012nL9FSU1tDVW0V1bXVVNVUUVVbdcxjU3XVtdWNtm+qztFXgybLsqy6KWax4DEr1mRZYrmxsraul2VZmFmmNwXuTo3XUOu11NQGj7Ve2+Flg/sMZtGZi07oe1XodyHuzkcff8S+w/vYd2QfHxz+gH2Hw8cj+4L5I/Vlh44eynSXAajxmk4RxEbmw6Wz0Adg5zSpeJJCv7uq9VoOVh5sGNjhfCLM6+aTyqpqqxp9PsPo37M/A/IHUJhfyJC+Q+ib17dTBF2WZZGTlUNOLIfsrOy6+dTHpuqys7Ibbd+auuys7E5xRNmZuDuO1x11tvVoNbHcWFk663UWMYul/dfJiSgzrEP2UYV+G9R6LZXVlRyuOszhqsMcqTpSP199hIqPK9h/ZP+xR+Ipgd7UDh+zGIX5hQzIH8CAngMY3n84kwZPalCWmC/ML2RAzwH0y+tHLCvWwVtCujIzwzCyYjq1FyXdKvSraqo4Un2kyTBOzDdX19T6yXWV1ZVp9yk3ltsgnEcNHMWAngMalKWGeZ/cPjoqFZETIq3QN7MZwB1ADLjb3Zem1A8B7gP6hW2WuPtjZlYCbAN2hE1fcver2qfrDf2j4h988mefbPV6hpGfk0/PnJ7k5+TXTT2ze9K7R28G9hpYt1xX10jb5LpeOb3o37M/hfmF5OfkK8BFpNNoMfTNLAYsB84HyoBNZrbW3bcmNbsJ+KO7/8rMRgKPASVh3ZvuPrZ9u32svrl9uW3abQ0CODWgG6vLjeUqlEUkMtI50p8I7HT3XQBmthqYBSSHvgN9wvm+wN727GQ6eub05KZzburolxUR6VLSOYMzGHgnabksLEv2I+BfzKyM4Cj/20l1Q83sFTN7zsy+cDydFRGR45NO6Dc29pF6ke9c4F53LwYuBO43syzgXWCIu48DrgP+08z6pKyLmS0ys1IzKy0vL2/dOxARkbSlE/plwClJy8UcO3xzBfBHAHffAOQBhe5+1N33heWbgTeBU1NfwN1Xunvc3eNFRS1+25eIiLRROqG/CRhuZkPNrAcwB1ib0uZt4DwAMxtBEPrlZlYUngjGzIYBw4Fd7dV5ERFpnRZP5Lp7tZktBp4kuBxzlbu/Zma3AqXuvhb4LvAbM7uWYOhngbu7mZ0D3Gpm1UANcJW77z9h70ZERJpl7p3rHhzxeNz1xegiIq1jZpvdPd5SO/3/tYhIhCj0RUQiRKEvIhIhCn0RkQhR6IuIRIhCX0QkQhT6IiIRotAXEYkQhb6ISIQo9EVEIkShLyISIQp9EZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJEIW+iEiEKPRFRCJEoS8iEiEKfRGRCFHoi4hEiEJfRCRCFPoiIhGSVuib2Qwz22FmO81sSSP1Q8xsvZm9YmZ/NbMLk+puCNfbYWYXtGfnRUSkdbJbamBmMWA5cD5QBmwys7XuvjWp2U3AH939V2Y2EngMKAnn5wCnA4OAdWZ2qrvXtPcbERGRlqVzpD8R2Onuu9z9Y2A1MCuljQN9wvm+wN5wfhaw2t2PuvtuYGf4fCIikgHphP5g4J2k5bKwLNmPgH8xszKCo/xvt2JdERHpIOmEvjVS5inLc4F73b0YuBC438yy0lwXM1tkZqVmVlpeXp5Gl0REpC3SCf0y4JSk5WLqh28SrgD+CODuG4A8oDDNdXH3le4ed/d4UVFR+r0XEZFWSSf0NwHDzWyomfUgODG7NqXN28B5AGY2giD0y8N2c8ws18yGAsOBl9ur8yIi0jotXr3j7tVmthh4EogBq9z9NTO7FSh197XAd4HfmNm1BMM3C9zdgdfM7I/AVqAauFpX7oiIZI4F2dx5xONxLy0tzXQ3RES6FDPb7O7xltrpP3JFRCJEoS8iEiEKfRGRCFHoi4hEiEJfRCRCFPoiIhGi0BcRiRCFvohIhCj0RUQiRKEvIhIhCn0RkQhR6IuIRIhCX0QkQhT6IiIRotAXEYkQhb6ISIQo9EVEIkShLyISIQp9EZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJkLRC38xmmNkOM9tpZksaqb/dzLaE0+tmdiCpriapbm17dl5ERFonu6UGZhYDlgPnA2XAJjNb6+5bE23c/dqk9t8GxiU9xRF3H9t+XRYRkbZK50h/IrDT3Xe5+8fAamBWM+3nAr9vj86JiEj7Sif0BwPvJC2XhWXHMLNPAUOBZ5KK88ys1MxeMrOL2txTERE5bi0O7wDWSJk30XYOsMbda5LKhrj7XjMbBjxjZq+6+5sNXsBsEbAIYMiQIWl0SURE2iKdI/0y4JSk5WJgbxNt55AytOPue8PHXcCzNBzvT7RZ6e5xd48XFRWl0SUREWmLdEJ/EzDczIaaWQ+CYD/mKhwzOw0oADYklRWYWW44XwhMBramrisiIh2jxeEdd682s8XAk0AMWOXur5nZrUCpuyc+AOYCq909eehnBPBrM6sl+IBZmnzVj4iIdCxrmNGZF4/HvbS0NNPdEBHpUsxss7vHW2qn/8gVEYkQhb6ISISkc8mmSOfhDkeOwIEDcPBg8Jg631Tdxx9nuvedS25uMOXlNT01V9+adXNzIaubHWO6w9GjUFnZcEq3rLHyT30KfvjDE9pthX53VlsbPJoFU2dQWwsffZReSDcV5lVVzb9GTg7061c/9e0LgwYF4SMB9+BDMDlwKioaD6bKypa3eTp69Dj2AyHxYZCYzJpePpF17q0P7fY4iMjObrg9Jkw4/uds6SVP+CtIx6ishC1b4OWXYePG4HHnzvr6xM7dUb9EyctVVfWBffBg8AvWnPz8hoFdVATDh9cvJ9elhnu/fsEvT2f5kOsuamubPlpt7kg2nbra2mCfqK09dj51ubq66brm1mupDhr/a2XAgPT+wmnqr57m2ubmBqHfwRT6XVFtLbzxRn24b9wIf/lL/dHYoEHwuc/BnDkQizW986cz3x7r5OTAmDHpBXbfvkF76VyysqBnz2CSLk2h3xW8/37DgN+0KThyBujdG+JxuO46mDgxCPvBjd4aSUREod/pHD4M//3fDYdp9uwJ6mIxOOMM+NrXgnCfOBFGjAjKRUTSoNDPpJoa2L69YcD/9a9BOQRn8idOhMWLg8fx46FXr8z2WUS6NIV+R9q7tz7gN26E0tLgShYIxrInTIAlS4KAnzgRTj45s/0VkW5HoX+iVFTA5s31Af/yy1BWFtRlZwcnNr/xjfphmlNP7X7XMYtIp6PQPx4HDgTj7Xv2wFtv1c+/8QZs21Z/nfynPw1f+EJ9wI8bp2vGRSQjFPpNcW8Y6qnBvmdPcM15sl69oKQEhg6FSy+tH6YpLOzgzouINC66oe8OH37YMMRTg/3QoYbr9O4dhHpJSXDknpgvKQlOug4YoH8KEpFOrfuGvjvs339sqCcHe+IkasJJJ9WH+JQpDUO9pAQKChTqItKldZ/Q378/uFFRcrBXVDRs06dPMPQydChMm3ZsqPfrp1AXkW6t+4R+Tg488EAQ3sOHwxe/2Hioi4hEWPcJ/ZNOCsboRUSkSbowXEQkQhT6IiIRotAXEYkQhb6ISIQo9EVEIiSt0DezGWa2w8x2mtmSRupvN7Mt4fS6mR1IqptvZm+E0/z27LyIiLROi5dsmlkMWA6cD5QBm8xsrbtvTbRx92uT2n8bGBfO9wduBuKAA5vDdXVtpYhIBqRzpD8R2Onuu9z9Y2A1MKuZ9nOB34fzFwBPufv+MOifAmYcT4dFRKTt0gn9wcA7SctlYdkxzOxTwFDgmdauKyIiJ146od/YzWi8ibZzgDXuXtOadc1skZmVmllpeXl5Gl0SEZG2SCf0y4BTkpaLgb1NtJ1D/dBO2uu6+0p3j7t7vKioKI0uiYhIW6QT+puA4WY21Mx6EAT72tRGZnYaUABsSCp+EphuZgVmVgBMD8tERCQDWrx6x92rzWwxQVjHgFXu/pqZ3QqUunviA2AusNrdPWnd/WZ2G8EHB8Ct7r6/fd+CiIiky5IyulOIx+NeWlqa6W6IiHQpZrbZ3eMttdN/5IqIRIhCX0QkQhT6IiIRotAXEYkQhb6ISIQo9EVEIkShLyISIQp9EZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJEIW+iEiEKPRFRCJEoS8iEiEKfRGRCFHoi4hEiEJfRCRCFPoiIhGi0BcRiRCFvohIhCj0RUQiRKEvIhIhaYW+mc0wsx1mttPMljTR5mtmttXMXjOz/0wqrzGzLeG0tr06LiIirZfdUgMziwHLgfOBMmCTma11961JbYYDNwCT3f1DMxuY9BRH3H1sO/dbRETaIJ0j/YnATnff5e4fA6uBWSltrgSWu/uHAO7+fvt2U0RE2kM6oT8YeCdpuSwsS3YqcKqZvWhmL5nZjKS6PDMrDcsvOs7+iojIcWhxeAewRsq8kecZDkwFioEXzOwMdz8ADHH3vWY2DHjGzF519zcbvIDZImARwJAhQ1r5FkREJF3pHOmXAackLRcDextp84i7V7n7bmAHwYcA7r43fNwFPAuMS30Bd1/p7nF3jxcVFbX6TYiISHrSCf1NwHAzG2pmPYA5QOpVOA8D0wDMrJBguGeXmRWYWW5S+WRgKyIikhEtDu+4e7WZLQaeBGLAKnd/zcxuBUrdfW1YN93MtgI1wL+7+z4zOwv4tZnVEnzALE2+6kdERDqWuacOz2dWPB730tLSTHdDRKRLMbPN7h5vqZ3+I1dEJEIU+iIiEaLQFxGJEIW+iEiEKPRFRCJEoS8iEiEKfRGRCFHoi4hEiEJfRCRCFPoiIhGi0BcRiRCFvohIhCj0RUQiRKEvIhIh6XxdokiHqKqqoqysjMrKykx3pUvKy8ujuLiYnJycTHdFOjGFvnQaZWVlnHTSSZSUlGDW2FczS1PcnX379lFWVsbQoUMz3R3pxDS8I51GZWUlAwYMUOC3gZkxYMAA/ZUkLVLoS6eiwG87bTtJh0JfJMWdd97JiBEjKCgoYOnSpW1+nt69e7djr0Tah8b0RVL88pe/5PHHH9fYuHRLOtIXSXLVVVexa9cuZs6cye23387ixYsBWLBgAddccw1nnXUWw4YNY82aNQBUVFRw3nnnMX78eEaNGsUjjzySye6LtEhH+tI5fec7sGVL+z7n2LGwbFmzTVasWMETTzzB+vXrefTRRxvUvfvuu/zpT39i+/btzJw5k0svvZS8vDweeugh+vTpwwcffMCkSZOYOXOmxtel01Loi6TpoosuIisri5EjR/Lee+8BwaWSN954I88//zxZWVn8/e9/57333uPkk0/OcG9FGpdW6JvZDOAOIAbc7e7HnN0ys68BPwIc+Iu7Xx6WzwduCpv92N3va4d+S3fXwhF5JuTm5tbNuzsADzzwAOXl5WzevJmcnBxKSkp02aR0ai2GvpnFgOXA+UAZsMnM1rr71qQ2w4EbgMnu/qGZDQzL+wM3A3GCD4PN4boftv9bEel4Bw8eZODAgeTk5LB+/XreeuutTHdJpFnpnMidCOx0913u/jGwGpiV0uZKYHkizN39/bD8AuApd98f1j0FzGifrotk3rx58ygtLSUej/PAAw/w2c9+NtNdEmlWOsM7g4F3kpbLgM+ltDkVwMxeJBgC+pG7P9HEuoPb3FuRDrBnzx4guGJnwYIFANx7770N2lRUVABQWFjIhg0bGn2eRBuRziSd0G/sMgRv5HmGA1OBYuAFMzsjzXUxs0XAIoAhQ4ak0SUREWmLdIZ3yoBTkpaLgb2NtHnE3avcfTewg+BDIJ11cfeV7h5393hRUVFr+i8iIq2QTuhvAoab2VAz6wHMAdamtHkYmAZgZoUEwz27gCeB6WZWYGYFwPSwTEREMqDF4R13rzazxQRhHQNWuftrZnYrUOrua6kP961ADfDv7r4PwMxuI/jgALjV3fefiDciIiItS+s6fXd/DHgspeyHSfMOXBdOqeuuAlYdXzdFRKQ96N47IiIRotAXSZG4tfK8efMy3RWRdqd774ikOFG3Vq6uriY7W79yklk60hdJknxr5VtuuYWxY8cyduxYxo0bx0cffQTAT3/6U0aNGsWYMWNYsmQJAFu2bGHSpEmMHj2aiy++mA8/DO40MnXqVG688UamTJnCHXfcQXl5OZdccgkTJkxgwoQJvPjiixl7rxJNOuyQTilDd1ZucGvlhQsXsnz5ciZPnkxFRQV5eXk8/vjjPPzww2zcuJH8/Hz27w8uRvvmN7/JXXfdxZQpU/jhD3/ILbfcwrLwxQ4cOMBzzz0HwOWXX861117L2Wefzdtvv80FF1zAtm3b2veNijRDoS/ShMmTJ3Pdddcxb948Zs+eTXFxMevWrWPhwoXk5+cD0L9/fw4ePMiBAweYMmUKAPPnz+eyyy6re56vf/3rdfPr1q1j69a6exVy6NAhPvroI0466aQOelcSdQp96ZQ6w52VlyxZwpe//GUee+wxJk2axLp163D3Vn9BSq9everma2tr2bBhAz179mzv7oqkRWP6Ik148803GTVqFNdffz3xeJzt27czffp0Vq1axeHDhwHYv38/ffv2paCggBdeeAGA+++/v+6oP9X06dP5xS9+Ube8pb3HsERaoCN9kSYsW7aM9evXE4vFGDlyJF/60pfIzc1ly5YtxONxevTowYUXXshPfvIT7rvvPq666ioOHz7MsGHDuOeeexp9zjvvvJOrr76a0aNHU11dzTnnnMOKFSs6+J1JlFniG4A6i3g87qWlpZnuhmTAtm3bGDFiRKa70aVpG0aXmW1293hL7TS8IyISIRreEZFuzR2qq+Hjj4Pp6NHG56urg6mqqvH5jqgbMQJ+85sTuz0U+pIxNTVw5EgwVVYGO//hw1BbG/yi1tbWT8nLzdU11zYK3n8fzj47vbaxGOTkQHZ2/dSey+m0zcpqPoybCujm6hsr66hR7FisbdsjJwfy8qAjLupS6EdAbW0QqKm/FOn84rSlTWrbo0frgz35sbq6YT8ffzxYJ11ZWcFkVj+fWE4EWnJdK6+07JL++U+4/PKW27kHH7pNHXGmLh8+3Hx9U8tt/bCNxSA3F3r0CKbEfGpZz57Qt2/T9U2Vpdbn5LQuoBuri8WC/ayzU+h3I0ePwsaN8PTTwfSXvwQBmxqu7SH1F6qpX6b8/PpfzsSRTOIxtaywED796WODvLFQT0zS0D//CXfdlele1KutDT5cmvqAqKlpPIBjsUz3vPtS6HdhNTXwyitBwD/zDLzwQnAEnZUF8TgsXAi9e6d3FJROXeIxO/vEBO62bVBQ0P7PK5mT+KDOycl0TyRBod+FuAfB+MwzQdA/+ywcOBDUnX46XHklnHsuTJkC/fpltKsi0kkp9Du5t96qP5J/5hl4992gvKQELrkEzjsPpk2Dk0/OaDellXSbZcmULnDaIVrefx/+8AdYtAg+85kg3K+4Atatg6lTg8u5du2C3bvh7rth7lwFfnu76KKLOPPMMzn99NNZuXIlAE888QTjx49nzJgxnHfeeQBUVFSwcOFCRo0axejRo3nwwQcB6N27d91zrVmzhgULFgCwYMECrrvuOqZNm8b111/Pyy+/zFlnncW4ceM466yz2LFjBwA1NTV873vfq3veu+66i6effpqLL7647nmfeuopZs+e3RGbQ7oZHWpk2KFD8Nxz9UM2r74alPfpE4T8NdcEQzannx6tE5ffeeI7bPlH+96XZuzJY1k2o+U7ua1atYr+/ftz5MgRJkyYwKxZs7jyyit5/vnnGTp0aN3tlG+77Tb69u3Lq+EPLXEP/ea8/vrrrFu3jlgsxqFDh3j++efJzs5m3bp13HjjjTz44IOsXLmS3bt388orr5Cdnc3+/fspKCjg6quvpry8nKKiIu655x4WLlx4fBtEIkmh38EqK+HPf66/wqa0NDghm5cXXF89d24wZDN+fHDCVDrenXfeyUMPPQTAO++8w8qVKznnnHPqvkmrf//+QHCb5NWrV9etV5DGWejLLruMWHhpysGDB5k/fz5vvPEGZkZVVVXd81511VV1wz+J1/vGN77B7373OxYuXMiGDRv47W9/207vWKJEsXKCVVcHwZ44kn/xxeDSylgMJk6EG24IjuQ///kg+CWQzhH5ifDss8+ybt06NmzYQH5+PlOnTmXMmDF1Qy/JmrrNcnJZZWVlg7rk2yz/4Ac/YNq0aTz00EPs2bOHqVOnNvu8Cxcu5Ktf/Sp5eXlcdtllOicgbaIx/XbgHhzB798PZWXBZZTLlsHMmTBgQBDo//EfsG8f/Ou/wqOPBm3//Ge47bbgRKwCv3M4ePAgBQUF5Ofns337dl566SWOHj3Kc889x+7duwHqhndSb5OcGN75xCc+wbZt26itra37i6Gp1xo8eDAA9957b1359OnTWbFiBdXhP1gkXm/QoEEMGjSIH//4x3XnCURaK61DBTObAdwBxIC73X1pSv0C4H8Bfw+LfuHud4d1NUA4Us3b7j6zHfqdFvf6f+1vbjpypOU2LbVv7N+8P/OZYLjm3HODYC8q6qh3Lm01Y8YMVqxYwejRoznttNOYNGkSRUVFrFy5ktmzZ1NbW8vAgQN56qmnuOmmm7j66qs544wziMVi3HzzzcyePZulS5fyla98hVNOOYUzzjiDioqKRl/r+9//PvPnz+fnP/855557bl35t771LV5//XVGjx5NTk4OV155JYsXLwZg3rx5lJeXM3LkyA7ZHtL9tHhrZTOLAa8D5wNlwCZgrrtvTWqzAIi7++JG1q9w996p5U1p662VP/gguD49NZRralr9VPToEfyXaH5+66bEOn36BEf3Q4a0/rWjTLcFbtnixYsZN24cV1xxRaP12obRle6tldM50p8I7HT3XeETrwZmAVubXauD5eUFd6hrLozTDW4NlUpndOaZZ9KrVy9+9rOfZbor0oWlE2+DgXeSlsuAzzXS7hIzO4fgr4Jr3T2xTp6ZlQLVwFJ3f/h4OtyU3r1hzZoT8cwincPmzZsz3QXpBtI5kdvY1eGpY0L/Dyhx99HAOuC+pLoh4Z8clwPLzOzTx7yA2SIzKzWz0vLy8jS7LiIirZVO6JcBpyQtFwN7kxu4+z53Pxou/gY4M6lub/i4C3gWGJf6Au6+0t3j7h4v0tnOSOtsX9/ZlWjbSTrSCf1NwHAzG2pmPYA5wNrkBmb2yaTFmcC2sLzAzHLD+UJgMp3sXIB0Hnl5eezbt0/h1Qbuzr59+8jTtb/SghbH9N292swWA08SXLK5yt1fM7NbgVJ3XwtcY2YzCcbt9wMLwtVHAL82s1qCD5ilyVf9iCQrLi6mrKwMDfG1TV5eHsXFxZnuhnRyLV6y2dHaesmmiEiUpXvJpv4jV0QkQhT6IiIRotAXEYmQTjemb2blwFuZ7sdxKgQ+yHQnOhFtj4a0PeppWzR0PNvjU+7e4jXvnS70uwMzK03nhEpUaHs0pO1RT9uioY7YHhreERGJEIW+iEiEKPRPjJWZ7kAno+3RkLZHPW2Lhk749tCYvohIhOhIX0QkQhT6bWBmp5jZejPbZmavmdm/heX9zewpM3sjfCwIy83M7jSznWb2VzMbn9l30P7MLGZmr5jZo+HyUDPbGG6LP4Q368PMcsPlnWF9SSb7fSKYWT8zW2Nm28N95PMR3zeuDX9P/mZmvzezvCjtH2a2yszeN7O/JZW1en8ws/lh+zfMbH5b+6PQb5tq4LvuPgKYBFxtZiOBJcDT7j4ceDpcBvgSMDycFgG/6vgun3D/Rnh31dD/BG4Pt8WHQOL7/a4APnT3zwC3h+26mzuAJ9z9s8AYgu0SyX3DzAYD1xB8neoZBDdtnEO09o97gRkpZa3aH8ysP3AzwRdYTQRuTnxQtJq7azrOCXiE4DuEdwCfDMs+CewI539N8L3CifZ17brDRPAdC08D5wKPEnzxzgdAdlj/eeDJcP5J4PPhfHbYzjL9HtpxW/QBdqe+pwjvG4lv3usf/rwfBS6I2v4BlAB/a+v+AMwFfp1U3qBdayYd6R+n8M/PccBG4BPu/i5A+DgwbNbYV04O7rhennDLgO8DteHyAOCAu1eHy8nvt25bhPUHw/bdxTCgHLgnHO6628x6EdF9w93/Dvxv4G3gXYKf92aiu38ktHZ/aLf9RKF/HMysN/Ag8B13P9Rc00bKusVlU2b2FeB9d0/+Atfm3m+33RahbGA88Ct3Hwf8k/o/3RvTrbdHOAQxCxgKDAJ6EQxhpIrK/tGSpt5/u20XhX4bmVkOQeA/4O7/FRa/l/gWsfDx/bC8xa+c7MImAzPNbA+wmmCIZxnQz8wSX9KT/H7rtkVY35fgi3e6izKgzN03hstrCD4EorhvAHwR2O3u5e5eBfwXcBbR3T8SWrs/tNt+otBvAzMz4P8A29z950lVa4HEWfX5BGP9ifJvhmfmJwEHE3/adXXufoO7F7t7CcEJumfcfR6wHrg0bJa6LRLb6NKwfbc5knP3fwDvmNlpYdF5BF8RGrl9I/Q2MMnM8sPfm8T2iOT+kaS1+8OTwHQLvoK2AJgelrVepk9wdMUJOJvgT6u/AlvC6UKCscengTfCx/5hewOWA28CrxJcyZDx93ECtstU4NFwfhjwMrB0ka+8AAAAfElEQVQT+L9AblieFy7vDOuHZbrfJ2A7jAVKw/3jYaAgyvsGcAuwHfgbcD+QG6X9A/g9wfmMKoIj9ivasj8A/yPcLjuBhW3tj/4jV0QkQjS8IyISIQp9EZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJEIW+iEiEKPRFRCLk/wMyMKttRHMbTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "e=[100,200,300,400,500,600,700,800,900,1000]\n",
    "s=[]\n",
    "fs=[]\n",
    "acc=[]\n",
    "for ee in e:\n",
    "    extra=ExtraTreesClassifier(n_estimators=ee,random_state=123)\n",
    "    extra.fit(X_train,y_train)\n",
    "    pre1=extra.predict(X_test)\n",
    "    accuracy=extra.score(X_test,y_test)\n",
    "    right=classifier(y_test,pre1)\n",
    "    ans=precision_recall_fscore(right)\n",
    "    ss=final(accuracy,ans[0],ans[2])\n",
    "    acc+=[accuracy]\n",
    "    fs+=[ans[2]]\n",
    "    s+=[ss]\n",
    "plt.plot(e,s,c='red',label='final')\n",
    "plt.plot(e,fs,c='blue',label='fscore')\n",
    "plt.plot(e,acc,c='green',label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier\n",
    "我們剛好設在200，也就是fscore的轉折點，之後的fscore和final就都差不多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1015f810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "g=[100,200,300,400,500]\n",
    "s=[]\n",
    "fs=[]\n",
    "acc=[]\n",
    "for gg in g:\n",
    "    grad=GradientBoostingClassifier(n_estimators=gg,learning_rate=0.02,random_state=1234)\n",
    "    grad.fit(X_train,y_train)\n",
    "    pre1=grad.predict(X_test)\n",
    "    accuracy=grad.score(X_test,y_test)\n",
    "    right=classifier(y_test,pre1)\n",
    "    ans=precision_recall_fscore(right)\n",
    "    ss=final(accuracy,ans[0],ans[2])\n",
    "    acc+=[accuracy]\n",
    "    fs+=[ans[2]]\n",
    "    s+=[ss]\n",
    "plt.plot(g,s,c='red',label='final')\n",
    "plt.plot(g,fs,c='blue',label='fscore')\n",
    "plt.plot(g,acc,c='green',label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們最後是使用加成機率的方式，但當時選的是以維最高的AdaBoostClassifier 和 GradientBoostingClassifier，但畫出圖表後發現\n",
    "BaggingClassifier 和 ExtraTreesClassifier 好像其實比 AdaBoostClassifier 更接近0.75，使用他們和GradientBoostingClassifier 搞不好準確率會高一些"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
